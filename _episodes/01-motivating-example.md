---
title: "Motivating Example"
teaching: 15
exercises: 5
questions:
- "How do most people organise their data and associated files?"
- "What are some common issues with not having a clear plan for the naming and storage of files?"
objectives:
- "Understand that it all starts here"
keypoints:
- "Good data organization is the foundation of any research project"
---

### The Horror

Today, many people organise the files associated with some sort of data project in the same manner as they've always done it. Namely, to name and save files in a sporadic fashion, often
differing from project to project. The results are waste in the forms of wasted time, money and effort, and mistakes, with files being lost, shared with the wrong people, or incorrect files
being used for subsequent analysis.

Have you ever experienced a conversation such as the following?

*Hey, have you got that data file that so-and-so did a while back?*
*Erm, that stuff to do with those blood-marker measurements?*
*Yeah, that's the one*
[wait 20 minutes]
*Found it. It was in an email. I'll forward it to you*
[receive a file called **data_final_17.xls**

If you have, you're not alone, and it might not seen that big of a deal. But consider the problems that surround this example. First, the exact file can't be identified. It's unclear exactly which file
is needed, what it relates to, who created it, when, how and which project it's associated with. Next, it's location is a mystery, with the file having to be searched for. Finally, it's location is found
to be an email, which means its access is limited, but its distribution is potentially open to anyone, for better or worse. Finally, the filename is completely ambiguous. How can you be so sure it's the 
correct file? Your only chance to is glean some information from the email that is was attached to, or the content of the file itself. And what does the '17' refer to? The 17th version? The 17th year? 
Some sort of the ID number?

This lesson will explain some key elements of project organisation. These are file-naming and folders, the use of meta-data and the concept of raw data.

Without these core ideas, the most sophisticated data analysis in the world will rest upon shakey foundations, and at an extreme, could lead to the failure of the entire project.

#### Example 1 - 'Westpac jumps the gun on profit' (The Sydney Morning Herald)

*"Westpac was forced to halt trading on its shares and deliver its annual profit briefing a day early after it accidentally sent its results by email to research analysts"*

#### Example 2 - 'The $24 Million "Clerical Error" at TransAlta' (The Register)

*"The mistake led to TransAlta, a big Canadian power generator, buying more US power transmission hedging contracts in May at higher prices than it should have. In a conference call, chief executive Steve Snyder said the snafu was "literally a cut-and-paste error in an Excel spreadsheet that we did not detect when we did our final sorting and ranking bids prior to submission,""*

#### Example 3 - 'University of Toledo Loses $2.4 Million in Projected Revenue' (The Toledo Blade)

*"UT officials have discovered an internal budgeting error that means they will have $2.4 million less to work with than anticipated. The mistake—a typo in a formula that led officials to overestimate projected revenue—was found Tuesday"*


These are big, headline-making examples, but similar problems are almost certainly widespread. There is an online list of [spreadsheet horror stories](http://www.eusprig.org/horror-stories.htm) by the The European Spreadsheet Risks Interest Group (EuSpRIG), 
along with a growing body of literature around the details of such errors (e.g. [Rajalingham, K., Chadwick, D. R., & Knight, B. (2008). Classification of spreadsheet errors. arXiv preprint arXiv:0805.4224.](https://arxiv.org/abs/0805.4224)).

However, the good news is that huge strides can be taken away from such potential errors by a handful of basic data management and spreadsheet principles.


### Exercise

Think about issues you've encounted over the years relating to data. What were they? Issues around finding data? Knowing what the data is when you do find it? Knowing what's been done to data and by whom? Etc.



